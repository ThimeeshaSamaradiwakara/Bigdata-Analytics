# -*- coding: utf-8 -*-
"""Task 02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x9UNQvvta2zBQVCCT0h_-VSpwmQFDUdM
"""

# Install PySpark
!pip install pyspark

# Import and create Spark session
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("Task02_Preprocessing") \
    .getOrCreate()

from google.colab import files
uploaded = files.upload()

# Load CSV into Spark DataFrame
df = spark.read.csv("Online.csv", header=True, inferSchema=True)

# Preview data
df.show(5)
df.printSchema()

# Drop nulls in key columns
clean_df = df.dropna(subset=["Quantity", "UnitPrice", "Country"])

from pyspark.sql.functions import col

clean_df = clean_df.withColumn("TotalValue", col("Quantity") * col("UnitPrice"))
clean_df.select("Quantity", "UnitPrice", "TotalValue").show(5)

from pyspark.ml.feature import VectorAssembler

assembler = VectorAssembler(
    inputCols=["Quantity", "UnitPrice"],
    outputCol="features"
)

final_df = assembler.transform(clean_df)
final_df.select("features", "TotalValue").show(5)

pandas_df = final_df.select("Quantity", "UnitPrice", "TotalValue").toPandas()
pandas_df.to_csv("Cleaned_Online.csv", index=False)

from google.colab import files
files.download("Cleaned_Online.csv")